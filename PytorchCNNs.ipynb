{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9533e0de-2c87-4309-8c71-73919457393c",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2977a103-bbbb-44c0-9756-2b9c94dcaba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torch.nn.functional as F  \n",
    "\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d052afd-6dab-4681-b7c9-8a7d0a02740a",
   "metadata": {},
   "source": [
    "## Set up Training Device and Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92ae7d0c-23f5-4b98-a357-5f97efd9567a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a16595a5-6f74-4272-a5a7-fa5fe3276648",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 100 # How often we print the train loss\n",
    "dtype = torch.float32 # Data type to use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d40768-c7e1-463f-8382-6b5d97f93210",
   "metadata": {},
   "source": [
    "## Import Data and Set up Training Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa5880e8-6e0f-4140-ab58-4c66c556f322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAIN = 49000 # Number of training samples out of 50000 total samples\n",
    "\n",
    "# Normalize Data\n",
    "transform = T.Compose([\n",
    "                T.ToTensor(),\n",
    "                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            ])\n",
    "\n",
    "# Set up a Data Loader + Sampler combination for Batch Training\n",
    "\n",
    "cifar10_train = dset.CIFAR10('./datasets', train=True, download=True,\n",
    "                             transform=transform)\n",
    "loader_train = DataLoader(cifar10_train, batch_size=64, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "cifar10_val = dset.CIFAR10('./datasets', train=True, download=True,\n",
    "                           transform=transform)\n",
    "loader_val = DataLoader(cifar10_val, batch_size=64, \n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
    "\n",
    "cifar10_test = dset.CIFAR10('./datasets', train=False, download=True, \n",
    "                            transform=transform)\n",
    "loader_test = DataLoader(cifar10_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d9a0d34-ce0c-4881-ad4c-5cb380c3887a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Augmented Data\n",
    "\n",
    "NUM_TRAIN = 49000\n",
    "\n",
    "\n",
    "transformAug = T.Compose([\n",
    "                T.ToTensor(),\n",
    "                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "                T.RandomAffine(degrees=15, translate=(0.15, 0.15)), # Image Shift & Turn\n",
    "                T.RandomHorizontalFlip(p=0.5) # Image Mirroring\n",
    "            ])\n",
    "\n",
    "# Data augmentation only on the training set\n",
    "cifar10_train = dset.CIFAR10('./datasets', train=True, download=True,\n",
    "                             transform=transform)\n",
    "loader_train_aug = DataLoader(cifar10_train, batch_size=64, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6014db1-7112-43e2-9bfe-6f31dd9adbbe",
   "metadata": {},
   "source": [
    "## Set Up Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e5e0fdc-23ce-4573-852e-4cfc3586322b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b6fafa5-8717-4c93-b66a-cedae1614ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model, device, dtype):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b58249fb-a227-41fa-9d00-6ffac524ecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, device, dtype, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                check_accuracy(loader_val, model, device, dtype)\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bb5a6d1-c4eb-44b2-a6c8-1214778f9aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_aug(model, optimizer, device, dtype, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on a CIFAR-10 augmented dataset using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    \n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train_aug):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                check_accuracy(loader_val, model, device, dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c77533-2f80-48c3-a993-28cf39389ad9",
   "metadata": {},
   "source": [
    "## No Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82b0cf41-96e9-4803-b347-bdd9e89a9e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "\n",
    "model = nn.Sequential(nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding='same'), \n",
    "                      nn.BatchNorm2d(32),\n",
    "                      nn.LeakyReLU(),\n",
    "                      nn.MaxPool2d(2, stride=2),\n",
    "                      nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding='same'),\n",
    "                      nn.BatchNorm2d(64),\n",
    "                      nn.LeakyReLU(), \n",
    "                      nn.MaxPool2d(2, stride=2),\n",
    "                      nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding='same'),\n",
    "                      nn.BatchNorm2d(64),\n",
    "                      nn.LeakyReLU(), \n",
    "                      nn.MaxPool2d(2, stride=2),\n",
    "                      nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding='same'),\n",
    "                      nn.BatchNorm2d(128),\n",
    "                      nn.LeakyReLU(), \n",
    "                      nn.MaxPool2d(2, stride=2),\n",
    "                      nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding='same'),\n",
    "                      nn.BatchNorm2d(256),\n",
    "                      nn.LeakyReLU(), \n",
    "                      nn.MaxPool2d(2, stride=2),\n",
    "                      Flatten(),   \n",
    "                      nn.Linear(256, 64),\n",
    "                      nn.Dropout(0.5),\n",
    "                      nn.BatchNorm1d(64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.Softmax()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636cce9d-f623-4963-b9ff-6636fdef639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "train_model(model, optimizer, device, dtype, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ff0e0d-1855-4c63-bfbe-c6d4f00c87a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_accuracy(loader_val, model, device, dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6306449-ec64-40e5-a24c-1fbd2dc1c7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "\n",
    "\n",
    "model2 = nn.Sequential(nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding='valid'), \n",
    "                      nn.BatchNorm2d(32),\n",
    "                      nn.LeakyReLU(),\n",
    "                      nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding='valid'), \n",
    "                      nn.BatchNorm2d(32),\n",
    "                      nn.LeakyReLU(),\n",
    "                      nn.MaxPool2d(2, stride=2),\n",
    "                      nn.Conv2d(in_channels=32, out_channels=64, kernel_size=2, padding='valid'),\n",
    "                      nn.BatchNorm2d(64),\n",
    "                      nn.LeakyReLU(),\n",
    "                      nn.Conv2d(in_channels=64, out_channels=64, kernel_size=2, padding='valid'),\n",
    "                      nn.BatchNorm2d(64),\n",
    "                      nn.LeakyReLU(),\n",
    "                      nn.MaxPool2d(2, stride=2),\n",
    "                      Flatten(),\n",
    "                      nn.Linear(2304, 1024),\n",
    "                      nn.Dropout(0.5),\n",
    "                      nn.BatchNorm1d(1024),\n",
    "                      nn.ReLU(),    \n",
    "                      nn.Linear(1024, 10),\n",
    "                      nn.Softmax()\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb6231b-172f-4283-aa2b-4d45fd238f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model2.parameters(), lr=lr)\n",
    "train_model(model2, optimizer, device, dtype, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a221317-8e73-4749-8e88-c3c37c349eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_accuracy(loader_val, model2, device, dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50673ef0-2f90-44b1-abe8-e50421a6fe11",
   "metadata": {},
   "source": [
    "## Include Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41bfa32e-00b0-47ab-a742-671b1be2cb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "\n",
    "model_aug = nn.Sequential(nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding='same'), \n",
    "                      nn.BatchNorm2d(32),\n",
    "                      nn.LeakyReLU(),\n",
    "                      nn.MaxPool2d(2, stride=2),\n",
    "                      nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding='same'),\n",
    "                      nn.BatchNorm2d(64),\n",
    "                      nn.LeakyReLU(), \n",
    "                      nn.MaxPool2d(2, stride=2),\n",
    "                      nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding='same'),\n",
    "                      nn.BatchNorm2d(64),\n",
    "                      nn.LeakyReLU(), \n",
    "                      nn.MaxPool2d(2, stride=2),\n",
    "                      nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding='same'),\n",
    "                      nn.BatchNorm2d(128),\n",
    "                      nn.LeakyReLU(), \n",
    "                      nn.MaxPool2d(2, stride=2),\n",
    "                      nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding='same'),\n",
    "                      nn.BatchNorm2d(256),\n",
    "                      nn.LeakyReLU(), \n",
    "                      nn.MaxPool2d(2, stride=2),\n",
    "                      Flatten(), \n",
    "                      nn.Linear(256, 64),\n",
    "                      nn.Dropout(0.5),\n",
    "                      nn.BatchNorm1d(64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.Softmax()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097f3720-50e5-4be5-8bf9-2fce39fa1679",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model_aug.parameters(), lr=lr)\n",
    "train_model_aug(model_aug, optimizer, device, dtype, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f1bc98-ed47-4458-8589-4d983fa164c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_accuracy(loader_val, model_aug, device, dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66e1bc21-3a1e-473a-ab94-d86b0bddfa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "\n",
    "\n",
    "model2_aug = nn.Sequential(nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding='same'), \n",
    "                      nn.BatchNorm2d(32),\n",
    "                      nn.LeakyReLU(),\n",
    "                      nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding='same'), \n",
    "                      nn.BatchNorm2d(32),\n",
    "                      nn.LeakyReLU(),\n",
    "                      nn.MaxPool2d(2, stride=2),\n",
    "                      nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding='same'),\n",
    "                      nn.BatchNorm2d(64),\n",
    "                      nn.LeakyReLU(),\n",
    "                      nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding='same'),\n",
    "                      nn.BatchNorm2d(64),\n",
    "                      nn.LeakyReLU(),\n",
    "                      nn.MaxPool2d(2, stride=2),\n",
    "                      nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding='same'),\n",
    "                      nn.BatchNorm2d(128),\n",
    "                      nn.LeakyReLU(),\n",
    "                      nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding='same'),\n",
    "                      nn.BatchNorm2d(128),\n",
    "                      nn.LeakyReLU(), \n",
    "                      nn.MaxPool2d(2, stride=2),\n",
    "                      Flatten(),\n",
    "                      nn.Linear(2048, 512),\n",
    "                      nn.Dropout(0.5),\n",
    "                      nn.BatchNorm1d(512),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(512, 10),\n",
    "                      nn.Softmax()\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c7205b-0b78-4da8-aee8-358bef99f2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model2_aug.parameters(), lr=lr)\n",
    "train_model_aug(model2_aug, optimizer, device, dtype, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf48c532-cf56-4bb0-bed4-27da16da0b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_accuracy(loader_val, model2_aug, device, dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f541e5-2b78-4403-bea6-ea74aa5fba68",
   "metadata": {},
   "source": [
    "## Select Best Model and Finish Training\n",
    "\n",
    "Based on the 10-epoch training results we pick the best model to further train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c49d44-6b0b-4556-81c0-b5826038b76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model2_aug.parameters(), lr=lr)\n",
    "train_model_aug(model2_aug, optimizer, device, dtype, epochs=100) # Train for 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d597b3-4357-4e3a-9d98-57f28f42afe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_accuracy(loader_val, model2_aug, device, dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70df4354-b790-4dbb-b90b-c8bf458b991f",
   "metadata": {},
   "source": [
    "## Model Structure and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a6b266-f9fd-4f14-9b1d-bae9f91200f5",
   "metadata": {},
   "source": [
    "The models tested consisted of variations of two distinct architectures: the first one being *(conv-batchnorm-relu-pool)xN -> (dense-dropout-batchnorm-relu)xM -> softmax* and the second one being *((conv-batchnorm-relu)x2 -> pool)xN -> (dense-dropout-batchnorm-relu)xM -> softmax* \n",
    "\n",
    "LeakyReLU was used instead of regular ReLU as the models seemed to converge much faster this way and with a small increase in accuracy (about 1-2%). A big increase in training speed also came from the use of batchnorm between the convolutional and dense layers (2d for the convolutional ones and 1d for the dense).\n",
    "\n",
    "\n",
    "### For the first architecture the models tested were the according:\n",
    "\n",
    "#### 1) Initial Model\n",
    "-32 filter conv layer (3x3 kernels with 'same' padding for standard dimensions) - batchnorm2d - leaky relu - MaxPool <br />\n",
    "-64 filter conv layer (3x3 kernels with 'same' padding) - batchnorm2d - leaky relu - MaxPool(stride=2) <br />\n",
    "-64 filter conv layer (3x3 kernels with 'same' padding) - batchnorm2d - leaky relu - MaxPool(stride=2) <br />\n",
    "-128 filter conv layer (3x3 kernels with 'same' padding) - batchnorm2d - leaky relu - MaxPool(stride=2) <br />\n",
    "-256 filter conv layer (3x3 kernels with 'same' padding) - batchnorm2d - leaky relu - MaxPool(stride=2) <br />\n",
    "-dense layer with 128 neurons (from 256 inputs) - relu - dense with 64 neurons - relu - dense with 10 neurons - softmax\n",
    "\n",
    "Validation Accuracy: 74%, Training Accuracy: 78.9% \n",
    "\n",
    "#### 2) Single Hidden Layer Dense Network\n",
    "Similar architecture with reduced depth of the dense neural network to only 3 layers: <br />\n",
    "\n",
    "-dense layer with 64 neurons (from 256 inputs) - relu - dense with 10 neurons - softmax\n",
    "\n",
    "Validation Accuracy: 77%, Training Accuracy: 83.39%\n",
    "\n",
    "We notice a faster convergence towards optimal weights as we can see an increase in both validation and training set accuracy after training for 10 epochs. If we increase the training time we expect similar results with the previous model but the computational cost is also decreased here so this architecture seems preferable (at least for 10 epochs). \n",
    "\n",
    "*Conclusion:* a single hidden layer dense network is capable of handling the features extracted through the convolutional layers in a more efficient way than a double hidden layer one.\n",
    "\n",
    "#### 3) Multiple Hidden Layer Dense Network\n",
    "This time we increase the features at the output of the convolutional layers by applying a single stride pooling layer at the last 2 levels and at the same time we use a multiple layer dense network to handle the output: <br />\n",
    "\n",
    "-dense layer with 512 neurons (from 1024 inputs) - relu - dense with 256 neurons - relu - dense with 128 neurons - relu - \n",
    "dense with 64 neurons - relu - dense with 10 neurons - softmax\n",
    "\n",
    "Validation Accuracy: 71%, Training Accuracy: 72.3% \n",
    "\n",
    "Again we see that a deeper dense network seems to be doing a much worse job when we restrict the training time, while even with an increased number of epochs it might still have issues with converging to a better minimum compared to the more shallow network\n",
    "\n",
    "#### 4) and 5) AvgPool \n",
    "\n",
    "By using the first two models but substituting MaxPool for AvgPool we get a slightly worse performance by 2-3% in each case so using MaxPool with this specific dataset seems optimal\n",
    "\n",
    "#### 6) Smaller kernels\n",
    "\n",
    "Changing the kernels of the second model to 2x2 kernels (and adjusting the padding to 'valid' - practically no padding to fit the right dimensions)\n",
    "\n",
    "Validation Accuracy: 68.5%, Training Accuracy: 72.8% which is worse than the initial 3x3 kernel model\n",
    "\n",
    "#### 6) Larger kernels\n",
    "\n",
    "Changing the kernels of the second model to 5x5 kernels (and this time keeping the padding to 'same' to fit the right dimensions)\n",
    "\n",
    "Validation Accuracy: 73.8%, Training Accuracy: 77.04% which is better than the 2x2 kernel model but still not as good as the original\n",
    "\n",
    "#### 7) Without Dropout and Batch Norm\n",
    "\n",
    "By removing the Dropout and BatchNorm1d layers from the dense NNs we get the following:\n",
    "\n",
    "Validation Accuracy: 70.3%, Training Accuracy: 79.37% so we see that without these two extra layers the network is prone to overfitting to the training set and increasing its training accuracy but at the same time doing worse on unknown data\n",
    "\n",
    "\n",
    "### For the second architecture the models tested were the according:\n",
    "\n",
    "#### 1) Initial Model\n",
    "\n",
    "\n",
    "-32 filter conv layer (3x3 kernels with 'valid' padding) - batchnorm2d - leaky relu <br />\n",
    "-32 filter conv layer (3x3 kernels with 'same' padding) - batchnorm2d - leaky relu <br />\n",
    "-MaxPool(stride=2) <br />\n",
    "-64 filter conv layer (3x3 kernels with 'valid' padding) - batchnorm2d - leaky relu <br />\n",
    "-64 filter conv layer (3x3 kernels with 'same' padding) - batchnorm2d - leaky relu <br />\n",
    "-MaxPool(stride=2) <br />\n",
    "-128 filter conv layer (3x3 kernels with 'valid' padding) - batchnorm2d - leaky relu <br />\n",
    "-256 filter conv layer (3x3 kernels with 'valid' padding) - batchnorm2d - leaky relu <br />\n",
    "-MaxPool(stride=2) <br />\n",
    "-dense layer with 64 neurons (from 256 inputs) - relu - dense with 10 neurons - softmax\n",
    "\n",
    "Validation Accuracy: 71.2%, Training Accuracy: 73.11% \n",
    "\n",
    "#### 2)  and 3) Combination of different kernels\n",
    "\n",
    "Similarly to the initial model but by swapping the kernels on the second convolutioal layer of each pair for 2x2 kernels we get the following results\n",
    " \n",
    "Validation Accuracy: 68.4%, Training Accuracy: 69.83% we notice again that the 2x2 kernels don't seem to be working equally well with the 3x3 ones on this particular problem\n",
    "\n",
    "By doing the same but this time substituting only the 3x3 kernels of first pair of convolutional layers for 5x5 kernels we get \n",
    "\n",
    "Validation Accuracy: 70.8%, Training Accuracy: 71.3% so similarly to what we noticed before the 5x5 kernels seem to be doing better than the 2x2 ones but still the results we get are optimal only in the case of 3x3 kernels\n",
    "\n",
    "#### 4), 5) and 6) Removing a pair of layers\n",
    "\n",
    "By removing the last pair of layers we can experiment with a simpler and thus much easier to train CNN: \n",
    "\n",
    "-32 filter conv layer (3x3 kernels with 'valid' padding) - batchnorm2d - leaky relu <br />\n",
    "-32 filter conv layer (3x3 kernels with 'valid' padding) - batchnorm2d - leaky relu <br />\n",
    "-MaxPool(stride=2) <br />\n",
    "-64 filter conv layer (3x3 kernels with 'valid' padding) - batchnorm2d - leaky relu <br />\n",
    "-64 filter conv layer (3x3 kernels with 'valid' padding) - batchnorm2d - leaky relu <br />\n",
    "-MaxPool(stride=2) <br />\n",
    "-dense layer with 512 neurons (from 1600 inputs) - relu - dense with 64 neurons - relu - dense with 10 neurons - softmax\n",
    "\n",
    "Validation Accuracy: 74.6%, Training Accuracy: 77.43% Despite the fact that this CNN is not as deep as the initial one it seems to be doing almost equally well \n",
    "\n",
    "By changing the 3x3 kernels to 2x2 kernels we get the following\n",
    "\n",
    "Validation Accuracy: 77.1%, Training Accuracy: 85.02% which is the best result we have got so far with the model however failing to generalize a much better training accuracy and overfitting to the data\n",
    "\n",
    "Finally we combine 2x2 and 3x3 layers in the follwoing way\n",
    "\n",
    "-32 filter conv layer (3x3 kernels with 'valid' padding) - batchnorm2d - leaky relu <br />\n",
    "-32 filter conv layer (3x3 kernels with 'valid' padding) - batchnorm2d - leaky relu <br />\n",
    "-MaxPool(stride=2) <br />\n",
    "-64 filter conv layer (2x2 kernels with 'valid' padding) - batchnorm2d - leaky relu <br />\n",
    "-64 filter conv layer (2x2 kernels with 'valid' padding) - batchnorm2d - leaky relu <br />\n",
    "-MaxPool(stride=2) <br />\n",
    "-dense layer with 512 neurons (from 2304 inputs) - relu - dense with 64 neurons - relu - dense with 10 neurons - softmax\n",
    "\n",
    "Validation Accuracy: 78.2%, Training Accuracy: 85.57% Similarly to the previous one, we get even better results but the model again seems to be overfitting to the training data\n",
    "\n",
    "### Data Augmentation\n",
    "\n",
    "We atempt to enhance our dataset by adding specific transformations to several of the images such as horizontal flip (with a probability of 0.5) and random affine, a combination of rotation and shift, both horizontal and vertical. \n",
    "\n",
    "We experiment with two transformations: \n",
    "\n",
    "-Random Horizontal Shift (p=0.5) and Random Affine (degrees=15 translate=(0.15,0.15)) <br />\n",
    "-Random Horizontal Shift (p=0.5) and Random Affine (degrees=30 translate=(0.2,0.2)) <br />\n",
    "\n",
    "The models used are the ones that did the best during the previous parts. <br />\n",
    "from the first architecture: Model number 2 as well as a similar version of this network with an extra convolutional layer added with 512 neurons before the dense layers, in order to see if a deeper model does better in the case of the augmented dataset. <br />\n",
    "From the second architecture: Model number 6 was used as well as a version of this model with an added pair of convolutional layers with 128 neurons each before the dense layers to compare again the more shallow model to one more capable of adapting to the dataset. <br />\n",
    "\n",
    "#### The results for the first augmentation after 10 epochs were the following:<br />\n",
    "\n",
    "##### Architecture 1: \n",
    "\n",
    "Best model: validation accuracy 76.5% and training accuracy* 82.5% <br />\n",
    "Deeper model: validation accuracy 75.4% and training accuracy 80.32% <br />\n",
    "\n",
    "##### Architecture 2: \n",
    "\n",
    "Best model: validation accuracy 75.5% and training accuracy* 82.3% <br />\n",
    "Deeper model: validation accuracy 82.2% and training accuracy 86.85% <br />\n",
    "\n",
    "*accuracy on the initial training set (not on the augmented one)\n",
    "\n",
    "#### The results for the second augmentation after 10 epochs were the following:<br />\n",
    "\n",
    "##### Architecture 1: \n",
    "\n",
    "Best model: validation accuracy 76.5% and training accuracy* 81.82% <br />\n",
    "Deeper model: validation accuracy 73.7% and training accuracy 79.72% <br />\n",
    "\n",
    "##### Architecture 2: \n",
    "\n",
    "Best model: validation accuracy 75.3% and training accuracy* 81.15% <br />\n",
    "Deeper model: validation accuracy 80.8% and training accuracy 85.75% <br />\n",
    "\n",
    "*accuracy on the initial training set (not on the augmented one) <br />\n",
    "\n",
    "For the first architecture we notice the initial model doing much better than the one with the extra layer while, for the second one, the addition of an extra pair of convolutional layers seems to be substantially improving the performance when training with the augmented dataset and the extra transformations seem to be affecting negatively the more shallow model's \n",
    "performance on the validation set. <br />\n",
    "\n",
    "After further training however (up to 100 epochs), the deeper models start having a better performance on the validation set (> 85%) while being able to almost memorize fully the training set (training accuracy > 98%). Still due to serious overfitting after that many epochs, there need to be more adjustments to hyperparameters and/or the architecture itself for the model to be able to generalize better the results.\n",
    "\n",
    "##### Model Choice: \n",
    "Only the best models for each architecture were left: Models 2 and 6 (model, model2) for architecture 1 and 2 respectively without the use of data augmentation as well as the same model for architecture 1 (model_aug) and the model with extra layers (model2_aug) for architecture 2 when using data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815ce3da-5f48-44ac-b7b4-8045ac5ccedc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
